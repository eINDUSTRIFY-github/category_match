{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eINDUSTRIFY-github/category_match/blob/main/Categorization_match.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code reads from two files: the first one is external supplier's categories, the second one is eIndustrify's most updated version of categories. It then compares the similarity of categories and match them, if the similarity score is below 0.4: meaning those are not great match, then the program will try to locate all sub/subsub categories within eindustrify's main category and match from there, despite low similarity score. This will make sure at least main category is correct. First cell is the program, second cell is translated PHP."
      ],
      "metadata": {
        "id": "eymRQfT8BZgv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# Specify the path for the input files\n",
        "eindustrify_path = 'Newly Formed Categories V4.xlsx'\n",
        "turtle_products_path = 'Turtle products details.xlsx'\n",
        "\n",
        "def generate_list_from_excel(file_path):\n",
        "    # Load the Excel file\n",
        "    excel_file = pd.ExcelFile(file_path)\n",
        "    data = []\n",
        "\n",
        "    # Iterate over all sheets in the Excel file\n",
        "    for sheet_name in excel_file.sheet_names:\n",
        "        sheet_df = excel_file.parse(sheet_name)\n",
        "\n",
        "        # Iterate over rows and columns to construct the data list\n",
        "        for row_index, row in sheet_df.iterrows():\n",
        "            for col_index, value in row.items():\n",
        "                data.append({'Sheet Name': sheet_name, 'Column Name': col_index, 'Value': value})\n",
        "    # Create a DataFrame from the data list\n",
        "    df = pd.DataFrame(data)\n",
        "    # Drop rows with NaN values in the 'Value' column\n",
        "    df.dropna(subset=['Value'], inplace=True)\n",
        "    # Create a new column 'Combined' by concatenating 'Sheet Name', 'Column Name', and 'Value'\n",
        "    df['Combined'] = df.apply(lambda x: f\"{x['Sheet Name']}/ {x['Column Name']}/ {x['Value']}\", axis=1)\n",
        "    # Keep only the 'Combined' column\n",
        "    df = df[['Combined']]\n",
        "    return df\n",
        "\n",
        "# Read the Excel files\n",
        "extracted_categories_df = generate_list_from_excel(eindustrify_path)\n",
        "turtle_products_df = pd.read_excel(turtle_products_path)\n",
        "\n",
        "# Extract the category lists from the DataFrames\n",
        "extracted_categories = extracted_categories_df.iloc[:, 0].tolist()\n",
        "turtle_products = turtle_products_df.iloc[:, 0].tolist()\n",
        "\n",
        "# Function to compute weighted cosine similarity between two lists of text\n",
        "def compute_weighted_cosine_similarity(vectorizer, extracted_categories, turtle_products):\n",
        "    # Transform the categories and products into TF-IDF vectors\n",
        "    extracted_vectors = vectorizer.transform(extracted_categories)\n",
        "    turtle_vectors = vectorizer.transform(turtle_products)\n",
        "\n",
        "    # Compute the cosine similarity matrix\n",
        "    similarity_matrix = cosine_similarity(turtle_vectors, extracted_vectors)\n",
        "\n",
        "    return similarity_matrix\n",
        "\n",
        "# Initialize the vectorizer and compute the similarity matrix\n",
        "vectorizer = TfidfVectorizer().fit(extracted_categories + turtle_products)\n",
        "similarity_matrix = compute_weighted_cosine_similarity(vectorizer, extracted_categories, turtle_products)\n",
        "\n",
        "# Find the best matches for each Turtle product based on cosine similarity\n",
        "matches = []\n",
        "for i, turtle_product in enumerate(turtle_products):\n",
        "    best_match_index = similarity_matrix[i].argmax()  # Find index of the highest similarity score\n",
        "    best_match_score = similarity_matrix[i, best_match_index]  # Get the highest similarity score\n",
        "    matches.append((turtle_product, extracted_categories[best_match_index], best_match_score))\n",
        "\n",
        "# Adjust matches with similarity score less than 0.4 by considering the main category\n",
        "adjusted_matches = []\n",
        "for i, (turtle_product, matched_category, similarity_score) in enumerate(matches):\n",
        "    if similarity_score < 0.4:  # Threshold for adjusting matches\n",
        "        main_category = turtle_product.split()[0].lower()  # Extract the main category from the product name\n",
        "        # Filter extracted categories to only those matching the main category\n",
        "        filtered_extracted_categories = [cat for cat in extracted_categories if cat.split('/')[0].strip().lower() == main_category]\n",
        "        if filtered_extracted_categories:\n",
        "            filtered_vectors = vectorizer.transform(filtered_extracted_categories)  # Transform filtered categories into vectors\n",
        "            # Compute new similarity matrix for filtered categories\n",
        "            new_similarity_matrix = cosine_similarity(vectorizer.transform([turtle_product]), filtered_vectors)\n",
        "            best_filtered_match_index = new_similarity_matrix[0].argmax()  # Find index of the highest similarity score in the new matrix\n",
        "            matched_category = filtered_extracted_categories[best_filtered_match_index]  # Update matched category\n",
        "            similarity_score = new_similarity_matrix[0, best_filtered_match_index]  # Update similarity score\n",
        "    adjusted_matches.append((turtle_product, matched_category, similarity_score))\n",
        "\n",
        "# Convert adjusted matches to DataFrame for saving to Excel\n",
        "adjusted_matches_df = pd.DataFrame(adjusted_matches, columns=['Turtle Product', 'Matched Category', 'Similarity Score'])\n",
        "\n",
        "# Save the DataFrame to an Excel sheet\n",
        "output_path = '/content/Adjusted_Matches.xlsx'\n",
        "adjusted_matches_df.to_excel(output_path, index=False)\n",
        "\n",
        "# Download the file automatically\n",
        "from google.colab import files\n",
        "files.download(output_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "T7QarIf7TA0c",
        "outputId": "5d933688-2955-49d4-feb2-24fbb04d65c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d7f3412a-f8d5-428a-9724-263cce41a2d6\", \"Adjusted_Matches.xlsx\", 190552)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eoXcdPJ_yQtj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is the PHP code"
      ],
      "metadata": {
        "id": "_V4_SWwvbLu8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k50W1P_7CGhY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}